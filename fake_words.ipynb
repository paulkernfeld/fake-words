{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- Fix german and polish word lists\n",
    "- Check all word lists\n",
    "- Check uber-alphabet\n",
    "- Maybe portuguese?\n",
    "- Another germanic language?\n",
    "- Print out punctuation and special letters\n",
    "\n",
    "Overview\n",
    "====\n",
    "Parlez-vous français? Sontre vait!\n",
    "\n",
    "\"Sontre vait\" is a French expression meaning, of course, nothing, because those aren't real French words. In fact, they are fake French words generated by training an algorithm on a French text. These words look to me, a non-French-speaker, like realistic French words, and hopefully they do to you, too. Of course, if you speak French, they probably look terrible, and you're probably already mad at me. Instead, take a look at some of the other languages that I've modeled!\n",
    "\n",
    "This project explores using a Markov model to assign likelihoods to words in an alphabet-based language, after being trained on a text in that language. These likelihoods are then used to generate realistic-looking fake words and to detect \"foreign-looking\" words.\n",
    "\n",
    "What is a \"word?\"\n",
    "----------------\n",
    "There are a lot of ways to define a \"word.\" For this project, I'll define a word to be a sequence of letters and certain approved punctuation marks. As far as approved punctuation, I have included the apostrophe for most alphabets. This means that a contraction like \"don't\" will be counted as a single word. This seems better than counting \"don't\" as two separate words, \"don\" and \"t.\"\n",
    "\n",
    "For languages with accented letters, I've chosen to model accented letters as if each one were its own distinct letter. So, my French \"alphabet\" includes 'E,' 'É,' 'È,' 'Ê,' and 'Ë' as separate \"letters.\" Confusingly, it is possible for a dictionary or text to contain letters that are not in the alphabet! For example, the letters 'J,' 'K,' 'W,' 'X,' and 'Y' are not considered to be part of the Italian alphabet, but they occur frequently in loan words.\n",
    "\n",
    "Below are the alphabets that I've defined for each language. If I've mauled your alphabet beyond all recognition, please send me an email; I'll be happy to fix it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How does anyone survive without these?\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latin: a b c d e f g h i l m n o p q r s t u v w x z\n",
      "german: a ä b c d e f g h i j k l m n o ö p q r s ß t u ü v w x y z\n",
      "spanish: a á b c d e é f g h i í j k l m n ñ o ó p q r s t u ú v w x y z\n",
      "french: a à â ä b c ç d e é è ê ë f g h i î ï j k l m n o ö ô p q r s t u û ü ù v w x y z '\n",
      "english: a b c d e f g h i j k l m n o p q r s t u v w x y z '\n",
      "polish: a ą b c ć d e ę f g h i l ł m n ń o ó p r s ś t u x y z ź ż\n",
      "italian: a à b c d e è é f g h i ì l m n o ò p q r s t u ù v z '\n"
     ]
    }
   ],
   "source": [
    "from fake_words.fake_words import LANGUAGES\n",
    "\n",
    "for language in LANGUAGES.values():\n",
    "    print u\"{}: {}\".format(language.name, \" \".join(list(language.alphabet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first pass: letter frequency\n",
    "================\n",
    "What constitutes a good fake word? \"Mait\" seems like a good fake French word to me, whereas \"xkzz\" does not seem like a good fake French word. How can we differentiate between these words?\n",
    "\n",
    "First up: letter frequency. 'R,' 'A,' 'I,' and 'T' are all commmon letters in French, whereas 'X,' 'K,' and 'Z' are not. This can be used to create a simple language model wherein words with common letters are judged to be likely, and words with uncommon letters are judged to be unlikely.\n",
    "\n",
    "For my first model, I'll define the likelihood of a word to be the product of the likelihood of each letter in the word. In this model, there is one parameter for each letter of the alphabet, which will be the frequency of that letter in the language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to learn these parameters, I have included a text for each language. It's possible to get maximum likelihood estimates for each letter frequency by counting the number of times that letter occurs, out of the total number of characters in the training document.\n",
    "\n",
    "This model makes it very easy for us to do computations, because all letters are independent of one another! Almost... *too* easy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a short method to print out the most likely words for each language, for each length of word. Since this model models word likelihood as a product of letter likelihoods, shorter words will tend to have higher likelihoods. In any language, the most likely word will be the empty string.\n",
    "\n",
    "Since an *M*-letter alphabet can form *M*^*N* words of length *N*, exploring the search space of all words is expensive when *N* is large. I have (slightly) optimized this search by pruning the search if the likelihood of the word I'm at is already lower than the likelihood of one of the top words that's already been found. I tried to create an heuristic search, but it did not work well.  With my current search, though, I can only generate words of up to five letters in a sane amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_WORD_LENGTH = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fake_words.fake_words import Language\n",
    "\n",
    "def print_for_max_gram(min_gram, max_gram):\n",
    "    languages = [Language(info, min_gram, max_gram) for info in LANGUAGES.values()]\n",
    "    \n",
    "    for language in languages:\n",
    "        for word_length in range(1, MAX_WORD_LENGTH + 1):        \n",
    "            top_words = language.top_words(word_length, 10)\n",
    "            top_words_formatted = u\", \".join(top_words)\n",
    "            print u\"{}-gram {} length-{}: {}\".format(max_gram, language.info.name, word_length, top_words_formatted)\n",
    "            print\n",
    "        print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, here we go..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram latin length-1: e, i, t, a, u, s, n, o, r, m\n",
      "\n",
      "1-gram latin length-2: ee, ie, ei, ii, et, te, ti, it, ae, ea\n",
      "\n",
      "1-gram latin length-3: eee, eie, eei, iee, iei, eii, iie, iii, ete, tee\n",
      "\n",
      "1-gram latin length-4: eeee, ieee, eeei, eeie, eiee, ieei, eiei, iiee, ieie, eeii\n",
      "\n",
      "\n",
      "1-gram german length-1: e, n, i, r, s, a, t, h, d, l\n",
      "\n",
      "1-gram german length-2: ee, ne, en, ie, ei, er, re, es, se, ae\n",
      "\n",
      "1-gram german length-3: eee, ene, een, nee, eie, iee, eei, ere, ree, eer\n",
      "\n",
      "1-gram german length-4: eeee, enee, eeen, eene, neee, ieee, eiee, eeei, eeie, eree\n",
      "\n",
      "\n",
      "1-gram spanish length-1: e, a, o, r, t, s, n, i, l, d\n",
      "\n",
      "1-gram spanish length-2: ee, ae, ea, aa, eo, oe, oa, ao, er, re\n",
      "\n",
      "1-gram spanish length-3: eee, eae, aee, eea, eaa, aae, aea, eeo, eoe, oee\n",
      "\n",
      "1-gram spanish length-4: eeee, eeea, aeee, eeae, eaee, eaae, eaea, eeaa, aeae, aeea\n",
      "\n",
      "\n",
      "1-gram french length-1: e, a, i, t, s, n, r, u, l, o\n",
      "\n",
      "1-gram french length-2: ee, ae, ea, ie, ei, te, et, se, es, ne\n",
      "\n",
      "1-gram french length-3: eee, eea, eae, aee, eei, iee, eie, eet, tee, ete\n",
      "\n",
      "1-gram french length-4: eeee, eaee, eeea, aeee, eeae, ieee, eeei, eeie, eiee, etee\n",
      "\n",
      "\n",
      "1-gram english length-1: e, t, a, o, n, i, h, s, r, d\n",
      "\n",
      "1-gram english length-2: ee, et, te, ea, ae, eo, oe, ne, en, ie\n",
      "\n",
      "1-gram english length-3: eee, ete, tee, eet, eae, aee, eea, eeo, eoe, oee\n",
      "\n",
      "1-gram english length-4: eeee, etee, eete, teee, eeet, eaee, eeea, aeee, eeae, eoee\n",
      "\n",
      "\n",
      "1-gram polish length-1: a, i, e, o, z, s, n, r, c, t\n",
      "\n",
      "1-gram polish length-2: aa, ia, ai, ii, ae, ea, ie, ei, oa, ao\n",
      "\n",
      "1-gram polish length-3: aaa, aia, aai, iaa, aii, iia, iai, iii, eaa, aae\n",
      "\n",
      "1-gram polish length-4: aaaa, iaaa, aaia, aaai, aiaa, iiaa, iaai, aaii, aiai, aiia\n",
      "\n",
      "\n",
      "1-gram italian length-1: e, i, a, o, n, t, r, l, s, c\n",
      "\n",
      "1-gram italian length-2: ee, ie, ei, ea, ae, eo, oe, ii, ia, ai\n",
      "\n",
      "1-gram italian length-3: eee, eie, iee, eei, eae, aee, eea, eeo, eoe, oee\n",
      "\n",
      "1-gram italian length-4: eeee, ieee, eeei, eeie, eiee, eaee, eeea, aeee, eeae, eoee\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_for_max_gram(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and it's terrible. These do not look like words at all. Nevertheless, there are a few useful things to be gleaned from this.\n",
    "\n",
    "Since a length-1 word is the same as a letter, the length-1 words serve as a double-check on the per-letter parameters. The English letters with highest likelihoods are, in order, \"ETAONI.\" This is close to the generally-accepted list of most frequent English letters, \"ETAOIN.\" The discrepancy may be because I'm using a slightly old text (*A Tale of Two Cities*), or just because the text is too short. Overall, the letter frequency ordering looks good for most languages.\n",
    "\n",
    "Another interesting thing to note here is that letter order does not matter. For example, after 'eee,' 'eet,' 'tee,' and 'ete' are all tied for second place in English.\n",
    "\n",
    "There is a very glaring problem with this approach. Although the letter 'E' is very common in English, it is very uncommon to have a word that is composed exclusively of the letter 'E.' To solve this problem, we need a model that models dependencies between letters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a Markov model\n",
    "===========\n",
    "I have chosen to use a Markov model to model the interactions between letters. Instead of modeling each letter individually, now each a word is modeled as a sequence of states, where each state corresponds to a letter.\n",
    "\n",
    "Train using... MLE?\n",
    "\n",
    "Modeling transitions between letters will create a lot of cases where the parameters aren't covered by the training data. For example, *A Tale of Two Cities* doesn't contain the letter sequences \"XZ\", \"ZX,\" or \"VF,\" amongst many others. In order to prevent this from zeroing out the likelihoods, I've used [add-one smoothing](https://en.wikipedia.org/wiki/Additive_smoothing), adding one to any bigram that doesnt appear in the training text.\n",
    "\n",
    "I'm handling the starts and ends of words specially to make the model generate more realistic words. For example, the model should capture that it's extremely uncommon for an English word to end with the letter \"Q.\" To do this, I added Markov chain states for start and end tokens. These behave more or less like letters, except that they must appear at the start and the end of each word, and they may not appear in the middle of the words. So, the word \"in\" is represented as, ```[\"start token\", \"I\", \"N\", \"end token\"]```.\n",
    "\n",
    "Just because I'm using the bigram model, doesn't mean that I need to stop using the 1-gram model. For the words below, I've multiplied in their 1-gram likelihoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-gram latin length-1: a, i, c, e, p, s, t, q, m, n\n",
      "\n",
      "2-gram latin length-2: er, is, in, at, es, en, it, am, ti, qu\n",
      "\n",
      "2-gram latin length-3: ere, ati, eri, ate, ter, int, iti, tis, ser, ite\n",
      "\n",
      "2-gram latin length-4: erer, ater, eres, atis, eren, eris, iter, iser, atin, erin\n",
      "\n",
      "\n",
      "2-gram german length-1: d, s, e, w, i, a, g, u, h, m\n",
      "\n",
      "2-gram german length-2: en, er, de, ei, se, in, st, es, ie, si\n",
      "\n",
      "2-gram german length-3: den, der, end, sen, dei, ser, ein, ien, ene, ier\n",
      "\n",
      "2-gram german length-4: dend, enen, ener, dein, ende, dene, eien, eier, send, sten\n",
      "\n",
      "\n",
      "2-gram spanish length-1: t, a, d, s, c, m, e, l, p, f\n",
      "\n",
      "2-gram spanish length-2: ar, te, an, er, es, en, de, ta, to, la\n",
      "\n",
      "2-gram spanish length-3: ter, tes, are, ten, ara, der, tar, des, lar, den\n",
      "\n",
      "2-gram spanish length-4: arer, ares, aren, arar, tere, tera, erer, eres, aran, eren\n",
      "\n",
      "\n",
      "2-gram french length-1: d, l, c, p, s, e, a, m, q, t\n",
      "\n",
      "2-gram french length-2: le, de, es, la, en, ai, an, ce, ll, se\n",
      "\n",
      "2-gram french length-3: les, des, len, den, lai, ler, let, der, det, ait\n",
      "\n",
      "2-gram french length-4: lent, dent, lait, lere, lese, lene, dere, dese, dene, lens\n",
      "\n",
      "\n",
      "2-gram english length-1: t, a, h, w, i, s, o, m, b, c\n",
      "\n",
      "2-gram english length-2: th, he, an, to, in, at, te, ar, ha, as\n",
      "\n",
      "2-gram english length-3: the, tha, thi, her, ath, hed, and, hen, tho, ith\n",
      "\n",
      "2-gram english length-4: ther, thed, then, athe, thes, than, thea, thin, here, ithe\n",
      "\n",
      "\n",
      "2-gram polish length-1: s, p, n, z, t, o, d, c, i, m\n",
      "\n",
      "2-gram polish length-2: ni, sz, ie, st, po, si, na, zy, pr, za\n",
      "\n",
      "2-gram polish length-3: nie, sie, zie, szy, sza, sze, nia, cie, szi, sta\n",
      "\n",
      "2-gram polish length-4: szie, niem, nier, niec, nien, siem, nies, onie, nied, sier\n",
      "\n",
      "\n",
      "2-gram italian length-1: d, a, p, s, c, i, t, e, l, n\n",
      "\n",
      "2-gram italian length-2: an, er, di, de, co, in, te, ar, al, at\n",
      "\n",
      "2-gram italian length-3: der, ere, ter, con, din, ser, are, cor, ano, den\n",
      "\n",
      "2-gram italian length-4: erer, dere, tere, arer, sere, eren, core, anon, ater, dera\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_for_max_gram(0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, much better! To me, these are starting to look much more realistic. To kick it up a notch, here is a Markov chain with a memory of two states — that is, a model that looks at trigrams in addition to bigrams and 1-grams. Bam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-gram latin length-1: o, r, c, w, x, v, g, m, l, u\n",
      "\n",
      "3-gram latin length-2: qu, in, co, pr, no, re, et, se, es, de\n",
      "\n",
      "3-gram latin length-3: que, qui, qua, con, quo, pro, est, ina, int, non\n",
      "\n",
      "3-gram latin length-4: cons, quam, coni, quae, cone, quid, quis, esse, sent, quod\n",
      "\n",
      "\n",
      "3-gram german length-1: ä, x, h, d, t, e, s, o, y, b\n",
      "\n",
      "3-gram german length-2: de, un, er, ge, si, di, ei, se, da, zu\n",
      "\n",
      "3-gram german length-3: und, der, ein, den, ich, die, gen, sei, ine, sch\n",
      "\n",
      "3-gram german length-4: eine, unde, sein, icht, sich, dern, iche, eind, scht, ders\n",
      "\n",
      "\n",
      "3-gram spanish length-1: t, ó, d, a, b, i, v, f, é, l\n",
      "\n",
      "3-gram spanish length-2: de, qu, th, co, to, la, es, do, se, no\n",
      "\n",
      "3-gram spanish length-3: the, que, con, lar, ent, est, qui, com, and, doñ\n",
      "\n",
      "3-gram spanish length-4: ther, quel, ente, este, lari, quer, esta, larc, dest, lara\n",
      "\n",
      "\n",
      "3-gram french length-1: e, h, è, m, q, z, p, u, ï, ô\n",
      "\n",
      "3-gram french length-2: de, qu, le, la, et, ce, pa, il, un, l'\n",
      "\n",
      "3-gram french length-3: que, les, des, qui, ent, qu', une, par, pas, ill\n",
      "\n",
      "3-gram french length-4: lest, lait, mait, dest, quel, ille, sait, ente, fait, ques\n",
      "\n",
      "\n",
      "3-gram english length-1: y, v, h, o, e, n, s, c, b, j\n",
      "\n",
      "3-gram english length-2: th, an, to, of, he, in, hi, ha, be, wa\n",
      "\n",
      "3-gram english length-3: the, and, tha, thi, ing, her, his, hat, tho, thr\n",
      "\n",
      "3-gram english length-4: ther, then, thea, they, that, them, thei, this, thes, ithe\n",
      "\n",
      "\n",
      "3-gram polish length-1: o, t, e, ł, n, ó, d, r, c, y\n",
      "\n",
      "3-gram polish length-2: po, na, ni, pr, si, za, st, do, pa, ta\n",
      "\n",
      "3-gram polish length-3: nie, się, prz, pod, sta, str, nia, dzi, czy, pro\n",
      "\n",
      "3-gram polish length-4: niem, nier, nied, niec, prze, niel, nien, przy, nies, nieg\n",
      "\n",
      "\n",
      "3-gram italian length-1: é, ', o, t, e, h, n, s, d, r\n",
      "\n",
      "3-gram italian length-2: di, co, de, in, th, ch, no, pr, qu, il\n",
      "\n",
      "3-gram italian length-3: che, del, the, con, pro, com, non, que, ing, col\n",
      "\n",
      "3-gram italian length-4: dell, nell, cone, alla, none, cont, coni, pera, ando, pare\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_for_max_gram(0, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One very strange fake word that I notice here is \"scht,\" in fake-German. This doesn't look like a good German word to me, because it does not have any vowels. Since the model never looks at the word as a whole, it has no way of \"counting\" the vowels, consonants, or any other category of letter to ensure that they are occuring in appropriate proportions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Generating fake words, finally!\n",
    "=================\n",
    "A functional system to model word probabilities can be used for many different things. To start with, we can find fake words, which are sequences of letters that look realistic, but aren't found in a dictionary.\n",
    "\n",
    "I'll just repeat the previous exercise, but using a dictionary for each language to eliminate sequences of letters that are already real words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_gram = 0\n",
    "max_gram = 3\n",
    "\n",
    "trigram_languages = [Language(info, min_gram, max_gram) for info in LANGUAGES.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-gram latin length-2: qu, co, th, po, di, pe, cu, ho, pa, ma, pu, ta\n",
      "3-gram latin length-3: con, ina, int, ine, ess, ing, inc, ati, the, vid, ant, pra\n",
      "3-gram latin length-4: sent, nons, pere, inte, quir, quiu, rest, cont, atis, ment, atio, estr\n",
      "\n",
      "3-gram german length-2: de, un, ge, si, di, ei, se, wa, we, ih, wi, ni\n",
      "3-gram german length-3: sei, ine, sch, ern, ung, sid, dem, ers, war, eit, nic, ber\n",
      "3-gram german length-4: unde, icht, sich, dern, iche, eind, scht, ders, dend, eing, sche, dens\n",
      "\n",
      "3-gram spanish length-2: qu, th, co, es, ma, an, po, of, pa, pr, di, us\n",
      "3-gram spanish length-3: the, ent, est, com, and, doñ, der, not, ine, ing, ust, thi\n",
      "3-gram spanish length-4: ther, quel, lari, quer, esta, larc, dest, lara, cone, quen, ques, lare\n",
      "\n",
      "3-gram french length-2: qu, pa, l', co, so, vo, po, mo, ch, av, pr, to\n",
      "3-gram french length-3: ent, qu', ill, deu, ett, com, qua, dev, ava, tou, res, dem\n",
      "3-gram french length-4: mait, dest, ille, ques, less, deur, quis, dess, rent, qu'i, dant, entr\n",
      "\n",
      "3-gram english length-2: th, wa, wi, wh, co, fo, st, sa, pr, ca, se, bu\n",
      "3-gram english length-3: tha, thi, ing, thr, ith, anc, ine, int, han, hav, hea, ind\n",
      "3-gram english length-4: ther, thea, thei, thes, ithe, thad, thed, thav, ande, thel, thim, hing\n",
      "\n",
      "3-gram polish length-2: po, na, ni, pr, si, za, st, do, pa, ta, cz, sz\n",
      "3-gram polish length-3: nie, się, prz, pod, sta, str, nia, dzi, czy, pro, nic, szy\n",
      "3-gram polish length-4: niem, nier, nied, niec, prze, niel, nien, przy, nies, nieg, nieś, nież\n",
      "\n",
      "3-gram italian length-2: th, ch, pr, an, of, gu, ri, tr, l', av, er, tm\n",
      "3-gram italian length-3: ing, and, dis, der, cor, all, ant, cos, anc, thi, cop, not\n",
      "3-gram italian length-4: dell, cone, cont, cona, sent, nont, dera, dele, cons, perg, anon, tent\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "for language in trigram_languages:\n",
    "    for word_length in range(2, MAX_WORD_LENGTH + 1):        \n",
    "        top_words = language.top_words(word_length, 100)\n",
    "        top_nonwords = [w for w in top_words if w not in language.dictionary]\n",
    "        top_nonwords_formatted = u\", \".join(top_nonwords[:12])\n",
    "        print u\"{}-gram {} length-{}: {}\".format(max_gram, language.info.name, word_length, top_nonwords_formatted)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The less familiar I am with a language, the better the fake words look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling words progressively\n",
    "===============\n",
    "What's the fun of making fake words if they can only be five letters long? Especially with German? As I mentioned above, the challenge is that the search space of *N*-letter words is too big when *N* > 5. Even with Latin's measly 23-letter alphabet, there are 148 million possible six-letter words. French, with 50 total letters, allows 15 billion six-letter words! So, instead of trying to cover the entire search space of long words, why not sample?\n",
    "\n",
    "For my first sampler, I sample each letter progressively from left to right, sampling the letter conditioned on the letters to its left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latin:  escestissim...,  eturitisini...,  mintiumentu...,  esserention...,  suntisturit...,  prenteresti...,  essentindem...,  terestentio...,  astesserati...,  etimuserise...\n",
      "\n",
      "german:  nenderenden...,  dersterneri...,  esendendesc...,  inererbenes...,  eserterende...,  neneredhare...,  iseinensene...,  eichtendast...,  ineinendere...,  andentenend...\n",
      "\n",
      "spanish:  anedicarion...,  seranoksean...,  sestasinesa...,  theroninari...,  entararenos...,  anesteranar...,  reandontine...,  marententer...,  andestradar...,  entereetera...\n",
      "\n",
      "french:  lestaiteste...,  unetesterai...,  daitererien...,  etaitestess...,  laitreteste...,  étaitestest...,  lansientess...,  saitententr...,  deuressaiti...,  destransest...\n",
      "\n",
      "english:  ofteneredle...,  enessiester...,  oneassister...,  therecerett...,  tomearening...,  hanothereth...,  andeareared...,  otheressire...,  itterendone...,  ingesseeter...\n",
      "\n",
      "polish:  inadanielec...,  zaczarazerz...,  razedziesta...,  inaperaniel...,  iniadanałon...,  dałaszadali...,  osieczamier...,  nierzelicho...,  staniazezna...,  odzeciedzie...\n",
      "\n",
      "italian:  dellorithio...,  retarentorr...,  ilerioriolo...,  rimissenele...,  receressere...,  citionotest...,  orelletenel...,  prontoranon...,  comonaleres...,  rimentendio...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for language in trigram_languages:\n",
    "    print u\"{}: {}\\n\".format(language.info.name, u\", \".join(language.sample_progressive(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I was hoping to do was to generate *N*-letter words by doing rejection sampling. This is definitely not going to work, though.\n",
    "\n",
    "Unfortunately, the sampler tends to end up in stationary distribution rather than reaching the end state, which means that it produces a bunch of words that are way too long. This reveals a weakness of using a Markov model: it doesn't know anything about the overall length of the word, so it doesn't get the hint that maybe it would be a good idea to stop adding letters to its already-100-letter-long word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling words with MCMC\n",
    "=============\n",
    "How can we cover our sample space more effectively? This question always seems to have the same answer: Markov Chain Monte Carlo. As such, I made a Metropolis-Hastings sampler that can make two different kinds of moves: it can replace a single letter, or swap two letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-letter latin samples: n, w, m, q, a, o\n",
      "1-letter latin top: x, v, w, u, r, o\n",
      "\n",
      "2-letter latin samples: ca, om, et, to, of, of\n",
      "2-letter latin top: qu, in, co, pr, no, re\n",
      "\n",
      "3-letter latin samples: tus, con, per, opu, nes, ofr\n",
      "3-letter latin top: que, qui, qua, con, quo, pro\n",
      "\n",
      "4-letter latin samples: cono, verm, tenu, lact, cont, acae\n",
      "4-letter latin top: cons, quam, coni, quae, cone, quid\n",
      "\n",
      "5-letter latin samples: stite, inerr, nuidu, inter, senib, stede\n",
      "5-letter latin top: quiss, quide, consu, quere, queri, sente\n",
      "\n",
      "6-letter latin samples: ulatic, depere, eterio, necens, oritam, undere\n",
      "6-letter latin top: quisse, essent, senter, intere, intent, interi\n",
      "\n",
      "7-letter latin samples: licatur, utimenb, etestal, contioc, prestil, wituiss\n",
      "7-letter latin top: sentere, sentent, senteri, essente, quitati, conisse\n",
      "\n",
      "8-letter latin samples: quissere, deriareg, thessena, sentesso, tationsi, antervid\n",
      "8-letter latin top: quissent, essenter, sentente, quitatis, quitatio, intenter\n",
      "\n",
      "9-letter latin samples: noniaecol, deatilici, eaturitil, anteatimu, certiosen, oridetius\n",
      "9-letter latin top: essentere, essentent, essenteri, intentere, conissent, intenteri\n",
      "\n",
      "10-letter latin samples: uteriterem, setilicesi, fritinessi, nustistimu, ilimistere, worunterit\n",
      "10-letter latin top: sententere, sententeri, quissentem, quitatisse, quissentis, quissentio\n",
      "\n",
      "\n",
      "1-letter german samples: v, ö, q, l, y, c\n",
      "1-letter german top: x, ä, h, ö, ü, ß\n",
      "\n",
      "2-letter german samples: ic, he, au, da, wi, ih\n",
      "2-letter german top: de, un, er, ge, si, di\n",
      "\n",
      "3-letter german samples: ich, die, der, spi, den, dem\n",
      "3-letter german top: und, der, ein, den, ich, die\n",
      "\n",
      "4-letter german samples: eins, undi, eine, unde, inem, that\n",
      "4-letter german top: eine, unde, sein, icht, sich, dern\n",
      "\n",
      "5-letter german samples: ungen, sande, undes, nicht, sichi, unens\n",
      "5-letter german top: under, unden, seine, einen, sicht, nicht\n",
      "\n",
      "6-letter german samples: hartha, hinden, sterla, eindas, einere, tatell\n",
      "6-letter german top: seinen, undern, unders, undend, einder, dender\n",
      "\n",
      "7-letter german samples: miteder, undesto, wundert, derlerb, ertente, inenden\n",
      "7-letter german top: undende, seinder, icheine, seinend, einende, seinden\n",
      "\n",
      "8-letter german samples: seingend, ungenenn, ungenden, inenderg, dernereu, deinscht\n",
      "8-letter german top: undender, undenden, einender, einenden, sicheine, nicheine\n",
      "\n",
      "9-letter german samples: eichender, dereinden, eingesesc, ihreinerg, einereine, icherterz\n",
      "9-letter german top: seinender, undeseine, seinenden, undendern, sicheinen, undenders\n",
      "\n",
      "10-letter german samples: tandeseine, derscherte, ichternena, genderende, windemeins, einenennen\n",
      "10-letter german top: undeseinen, seineseine, seindender, seinendern, undereinen, seinenders\n",
      "\n",
      "\n",
      "1-letter spanish samples: d, f, p, h, e, q\n",
      "1-letter spanish top: í, ó, é, u, v, t\n",
      "\n",
      "2-letter spanish samples: he, te, di, ou, se, wi\n",
      "2-letter spanish top: de, qu, th, co, to, la\n",
      "\n",
      "3-letter spanish samples: abu, nor, the, mem, the, nes\n",
      "3-letter spanish top: the, que, con, lar, ent, est\n",
      "\n",
      "4-letter spanish samples: rest, henc, stam, vert, lary, lart\n",
      "4-letter spanish top: ther, quel, ente, este, lari, quer\n",
      "\n",
      "5-letter spanish samples: itacc, entod, lasti, noted, estac, doncm\n",
      "5-letter spanish top: quent, ented, ested, enter, thera, there\n",
      "\n",
      "6-letter spanish samples: lartar, inteda, mentro, ingurw, therto, misabu\n",
      "6-letter spanish top: entent, estent, quente, quelar, dested, queste\n",
      "\n",
      "7-letter spanish samples: tranter, tenestá, starier, esterme, qualath, comalos\n",
      "7-letter spanish top: entente, estente, destent, coneste, quested, quelari\n",
      "\n",
      "8-letter spanish samples: enotereg, perenten, astandad, quienten, derthere, dertaing\n",
      "8-letter spanish top: quentent, entented, estented, ententer, estenter, destente\n",
      "\n",
      "9-letter spanish samples: starindon, elderentq, noterareg, andontant, enderstat, itormaraz\n",
      "9-letter spanish top: ententent, estentent, quentente, destented, questente, conestent\n",
      "\n",
      "10-letter spanish samples: prententow, thertareso, petiontese, ententeste, querestere, larsenters\n",
      "10-letter spanish top: ententente, estentente, quentented, quententer, destentent, conestente\n",
      "\n",
      "\n",
      "1-letter french samples: m, é, x, p, â, d\n",
      "1-letter french top: è, z, q, u, p, m\n",
      "\n",
      "2-letter french samples: pr, fa, de, su, ca, n'\n",
      "2-letter french top: de, qu, le, la, et, ce\n",
      "\n",
      "3-letter french samples: ser, les, vol, con, enu, lar\n",
      "3-letter french top: que, les, des, qui, ent, qu'\n",
      "\n",
      "4-letter french samples: desq, rest, denc, cess, sait, tell\n",
      "4-letter french top: lest, lait, mait, dest, quel, ille\n",
      "\n",
      "5-letter french samples: desse, pailb, quenc, delat, grant, enait\n",
      "5-letter french top: était, avait, illes, quest, laite, maite\n",
      "\n",
      "6-letter french samples: d'aien, unette, sontri, devait, étaita, lerivi\n",
      "6-letter french top: quelle, entait, entent, delles, dement, étaite\n",
      "\n",
      "7-letter french samples: sonstes, commerm, centent, ettereg, remente, renfans\n",
      "7-letter french top: quelles, lestait, destait, comment, dellest, laitait\n",
      "\n",
      "8-letter french samples: faitesti, trenteur, voistaid, faitense, aventerm, rentaieu\n",
      "8-letter french top: étaitait, avaitait, avaitent, lestaite, questait, destaite\n",
      "\n",
      "9-letter french samples: laitaitai, senverche, raintentr, enommenti, consierte, entretous\n",
      "9-letter french top: illestait, ententait, ententent, lestaient, dementait, entaitait\n",
      "\n",
      "10-letter french samples: unemencesu, literiente, mentenutes, maitenoura, availlerin, tommentell\n",
      "10-letter french top: lestaitait, lestaitent, dellestait, destaitait, destaitent, maitentait\n",
      "\n",
      "\n",
      "1-letter english samples: l, q, g, r, g, t\n",
      "1-letter english top: v, h, y, u, z, s\n",
      "\n",
      "2-letter english samples: on, sm, th, sp, wi, th\n",
      "2-letter english top: th, an, to, of, he, in\n",
      "\n",
      "3-letter english samples: his, rea, hic, mis, tha, lou\n",
      "3-letter english top: the, and, tha, thi, ing, her\n",
      "\n",
      "4-letter english samples: thes, hand, gert, witi, hery, them\n",
      "4-letter english top: ther, then, thea, they, that, them\n",
      "\n",
      "5-letter english samples: theal, nouts, hater, thent, harel, yough\n",
      "5-letter english top: there, thers, thery, thent, theri, thand\n",
      "\n",
      "6-letter english samples: heretc, theraf, theark, sonalt, hinget, theare\n",
      "6-letter english top: theres, therea, thered, theree, thathe, therem\n",
      "\n",
      "7-letter english samples: conerge, itterg', withand, tereses, thereti, theatin\n",
      "7-letter english top: thather, theress, therear, therest, theread, thereat\n",
      "\n",
      "8-letter english samples: thereerv, thearess, thatents, therearc, hationee, itheress\n",
      "8-letter english top: thathere, thereand, theather, therethe, thathers, therther\n",
      "\n",
      "9-letter english samples: thaterear, therethem, therverty, alothinto, ressither, hadesterv\n",
      "9-letter english top: thereathe, therether, thatheres, theathere, thatherea, thathered\n",
      "\n",
      "10-letter english samples: hinethathe, whereeress, thatenithe, histerearr, pritherear, witithered\n",
      "10-letter english top: thereather, therethere, therithere, thatheress, thatherear, thereathen\n",
      "\n",
      "\n",
      "1-letter polish samples: ń, ć, n, u, y, h\n",
      "1-letter polish top: ż, ń, ź, ś, ł, ę\n",
      "\n",
      "2-letter polish samples: co, rz, na, ry, sa, in\n",
      "2-letter polish top: po, na, ni, pr, si, za\n",
      "\n",
      "3-letter polish samples: cze, był, anu, ołę, prz, zec\n",
      "3-letter polish top: nie, się, prz, pod, sta, str\n",
      "\n",
      "4-letter polish samples: nieg, strz, robn, podz, nien, sieg\n",
      "4-letter polish top: niem, nier, nied, niec, prze, niel\n",
      "\n",
      "5-letter polish samples: niect, postr, rosta, strzy, panie, nielo\n",
      "5-letter polish top: niego, niecz, nieni, niedz, nierz, podzi\n",
      "\n",
      "6-letter polish samples: zalnim, tanied, czasta, lemneg, upierg, nionia\n",
      "6-letter polish top: nienie, niedzi, nierze, nierzy, nieczy, podzie\n",
      "\n",
      "7-letter polish samples: obieram, postacz, paniers, nierzyn, niedzie, niatera\n",
      "7-letter polish top: nieniem, nienier, nienied, niedzie, nieniec, nieniel\n",
      "\n",
      "8-letter polish samples: niedzieś, strzyles, nierodos, anieczys, biecicze, teraczuł\n",
      "8-letter polish top: niedziem, niedzier, niedzied, niedziec, niedziel, niedzien\n",
      "\n",
      "9-letter polish samples: zanierzel, onieszczn, panieniel, podzieczy, panienien, ziacznier\n",
      "9-letter polish top: nienienie, nieniedzi, nienierze, nienierzy, nienieczy, podzienie\n",
      "\n",
      "10-letter polish samples: zieczeczęd, baniedzind, zacciebary, nastranieg, przedziedn, strzeranym\n",
      "10-letter polish top: nienieniem, nienienied, niedzienie, nieniedzie, nienieniec, nienieniel\n",
      "\n",
      "\n",
      "1-letter italian samples: è, t, b, h, o, v\n",
      "1-letter italian top: é, ', ù, ì, ò, è\n",
      "\n",
      "2-letter italian samples: of, an, tu, an, ve, so\n",
      "2-letter italian top: di, co, de, in, th, ch\n",
      "\n",
      "3-letter italian samples: del, vin, alg, dif, ess, tri\n",
      "3-letter italian top: che, del, the, con, pro, com\n",
      "\n",
      "4-letter italian samples: prec, orta, priv, nell, dior, pere\n",
      "4-letter italian top: dell, nell, cone, alla, none, cont\n",
      "\n",
      "5-letter italian samples: resse, divem, deren, fanon, lated, pront\n",
      "5-letter italian top: della, delle, dello, dell', nella, quell\n",
      "\n",
      "6-letter italian samples: averee, intent, orallo, callod, onchis, nonoio\n",
      "6-letter italian top: quella, conell, nonell, inella, delleo, andell\n",
      "\n",
      "7-letter italian samples: seteret, thiscom, nontent, pelcono, liorenz, sullect\n",
      "7-letter italian top: conella, nonella, andella, content, conelle, dellect\n",
      "\n",
      "8-letter italian samples: solitato, costerag, prempers, ionatent, 'all'alt, prittera\n",
      "8-letter italian top: contente, sentente, nontente, contenti, cononell, tentente\n",
      "\n",
      "9-letter italian samples: dirnionon, secndever, giceresse, comentene, dellegall, antedell'\n",
      "9-letter italian top: antentent, sententen, nontenten, contenter, antention, gutentent\n",
      "\n",
      "10-letter italian samples: liacorimvg, nellitenta, diononell', conichenbe, piontaters, destentele\n",
      "10-letter italian top: antentente, comentente, dellatente, mententent, contentera, sententera\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "for language in trigram_languages:\n",
    "    for word_length in xrange(1, 13):\n",
    "        samples, top = language.sample_mh(word_length, max_to_store=6, n_runs=100, n_samples=1000*word_length)\n",
    "\n",
    "        samples_joined = u\", \".join(word for word, prob in samples[:6])\n",
    "        print u\"{}-letter {} samples: {}\".format(word_length, language.info.name, samples_joined)\n",
    "        \n",
    "        top_joined = \", \".join(word for prob, word in reversed(sorted(top, key=itemgetter(0))))\n",
    "        print u\"{}-letter {} top: {}\\n\".format(word_length, language.info.name, top_joined)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encouragingly, these sampled words match our exhaustively-searched words well! This indicates that the sampler is probably not completely broken.\n",
    "\n",
    "These words looks pretty good, up to about eight letters. Once the words get long, certain sequences of letters start to repeat. This makes a lot of sense, since the model is only aware of the neighborhood around each letter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Detecting foreign-looking words\n",
    "=================\n",
    "Time for some more fun! For this tangent, I'll go through the dictionary of each language to find words that seem to belong to other languages. Some of these are obviously loan words, but other ones (e.g. for Latin) just look foreign.\n",
    "\n",
    "In order to get a ranking, I've simply taken the ratio of the likelihood in the destination languages to the likelihood in the source language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latin words that look german: trochleis, echeneideis, ichneumoneis, andrachnen, echeneides\n",
      "latin words that look spanish: charazarier, judaismom, transfigurabas, transfigurandos, affigurabas\n",
      "latin words that look french: transfigurans, chondrilles, deurier, transfigurent, brancham\n",
      "latin words that look english: atheismom, branchad, heirai, chelyin, spathad\n",
      "latin words that look polish: zelotypiad, chrysopastom, zelotypam, zelotypas, brachypotad\n",
      "latin words that look italian: leopardale, leopardales, leopardalim, leopardali, leopardaleis\n",
      "german words that look latin: --------------------------------------------------------------------------, (http://creativecommons.org/licenses/by-nc/3.0/deed.de)., computersimulation, quantitativ, antiquariat\n",
      "german words that look spanish: parlamentarismus, quadratkilometer, violoncello, quantitativ, imperialismus\n",
      "german words that look french: portemonnaie, saisontreffer, europaparlament, violoncello, quantitativ\n",
      "german words that look english: oppositionspolitiker, journalismus, sympathisant, saisontor, saisonfinale\n",
      "german words that look polish: psychosozial, psychologie, nationalsozialismus, europapolitik, kolonialismus\n",
      "german words that look italian: --------------------------------------------------------------------------, (http://creativecommons.org/licenses/by-nc/3.0/deed.de)., bruttosozialprodukt, quadratkilometer, computersimulation\n",
      "spanish words that look latin: cumquibus, tumultuariamente, tumultuoso, tumultuosamente, eritroxiláceo\n",
      "spanish words that look german: fahrenheit, gerundense, leiden, zurdera, zurdir\n",
      "spanish words that look french: veintitrés, maitén, moisés, tournée, soufflé\n",
      "spanish words that look english: washingtoniano, whisky, hinnible, adstringir, befar\n",
      "spanish words that look polish: zarzoso, rociniego, roznar, eczema, zarzagán\n",
      "spanish words that look italian: infanzonazgo, nitroglicol, paleopatológico, ultramicroscópico, egipciaco\n",
      "french words that look latin: praesidiums, praesidium, thyreostimuline, aegopodiums, caesiums\n",
      "french words that look german: knickerbockers, breitschwanz, weltanschauungs, fahrenheit, zwiebacks\n",
      "french words that look spanish: knickerbockers, erythroblastose, zootechnicien, benzaldehyde, sweepstakes\n",
      "french words that look english: knickerbockers, sweepstakes, sweepstake, skinheads, washingtonia\n",
      "french words that look polish: biodynamies, zymotechnies, teledynamies, biodynamie, dyschromatopsie\n",
      "french words that look italian: benzodiazepine, benzodiazepines, aggiornamentos, benzonaphtols, benzaldehyde\n",
      "english words that look latin: omnibusses, omnicompetent, pseudoscorpions, pseudoscientist, pseudoscorpion\n",
      "english words that look german: weltschmerzes, zeitgebers, braunschweigers, zeitgeber, braunschweiger\n",
      "english words that look spanish: haciendados, vocabulary, pseudoscorpion, vocabularies, zarzuelas\n",
      "english words that look french: vouvray, etiquettes, vouvrays, trouveurs, oeuvres\n",
      "english words that look polish: psychodynamic, psychodynamics, psychobiologies, podzolization, psychobiography\n",
      "english words that look italian: razzamatazzes, razzamatazz, razzmatazzes, pseudoscorpion, pseudoscorpions\n",
      "polish words that look latin: videokonferencji, radiointerferometria, radiointerferometrii, multiinstrumentalisty, fortissimu\n",
      "polish words that look german: wielkokomórkowe, nawiewiewie, reinwestowane, ewangelie, wielkoskalowe\n",
      "polish words that look spanish: radiointerferometria, endowaskularnej, banderillerowi, endowaskularna, radiointerferometrię\n",
      "polish words that look french: neurotransplantations, neurotransplantacjami, savoir, neurotransplantacji, neurotransplantacje\n",
      "polish words that look english: endowaskularnej, banderillerowi, endowaskularna, wincentowie, parkinsonowi\n",
      "polish words that look italian: videokonferencji, radiointerferometria, ultrarentgenowski, immunofluorescencji, antykardiolipinowych\n",
      "italian words that look latin: cumquibus, tumultueremo, tumultuerei, tumultueresti, omnibus\n",
      "italian words that look german: kinderheim, wehrmacht, fahrenheit, weltanschauung, einsteini\n",
      "italian words that look spanish: clownescamente, blablabla, clownesca, workshop, clownesco\n",
      "italian words that look french: connaisseur, connaisseuse, cloisonne, nouveau, tourniquet\n",
      "italian words that look english: workshop, halloween, showdown, shocking, whiskey\n",
      "italian words that look polish: niego, czechi, czeche, garzera, spaniel\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from fake_words.fake_words import try_to_store\n",
    "\n",
    "N_TO_STORE = 5\n",
    "\n",
    "# Loop over every pair of languages\n",
    "for language_source in trigram_languages:\n",
    "    for language_dest in trigram_languages:\n",
    "        # A heap to store our best results\n",
    "        best_words = []\n",
    "\n",
    "        if language_dest is language_source:\n",
    "            continue\n",
    "    \n",
    "        for word in language_source.dictionary:\n",
    "            word_with_tokens = u\" {} \".format(word)\n",
    "            # Subtraction produces a ratio because these are log probabilities\n",
    "            ratio = language_dest.get_word_prob(word_with_tokens) - language_source.get_word_prob(word_with_tokens)\n",
    "            try_to_store(best_words, word, ratio, N_TO_STORE)\n",
    "\n",
    "        best_words_pretty = \", \".join(word for prob, word in reversed(sorted(best_words, key=itemgetter(0))))\n",
    "        print u\"{} words that look {}: {}\".format(language_source.info.name, language_dest.info.name, best_words_pretty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, now I'm having fun!\n",
    "\n",
    "I always feel slightly offended when I see the words that look English. \"Whiskey.\" \"Branchad.\" \"Spathad.\" \"Hinnible!\" Is this what English looks like to non-English-speakers? To make myself feel better, I imagine a heavy-set German man with a disproportionately large mustache saying, \"braunschweiger,\" \"trochleis,\" and \"weltschmerzes\" very seriously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Hopefully this article has illustrated the strengths and weaknesses of using a Markov model for word structure.\n",
    "\n",
    "Thanks\n",
    "------\n",
    "Thanks to my brother Eric for statistics help, and..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
